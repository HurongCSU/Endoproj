{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(849, 6097)\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "import joblib\n",
    "\n",
    "file_feature = \"./csv/endometrium.csv\"\n",
    "file_train = \"./csv/train.csv\"\n",
    "file_validate = \"./csv/validation.csv\"\n",
    "file_test = \"./csv/test.csv\"\n",
    "\n",
    "f = open(file_feature)\n",
    "csv_f = csv.reader(f)\n",
    "features = next(csv_f)\n",
    "dataset = pd.read_csv(file_feature, names=features, usecols=range(1,6098), dtype=np.float64, skiprows=1, low_memory=False)\n",
    "f = open(file_train)\n",
    "csv_f = csv.reader(f)\n",
    "features = next(csv_f)\n",
    "dataset_train = pd.read_csv(file_train, names=features, usecols=range(1,1), dtype=np.float64, skiprows=1, low_memory=False)\n",
    "\n",
    "with open('./csv/train.csv','r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    train_list = [row[1] for row in reader]\n",
    "with open('./csv/validation.csv','r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    validation_list = [row['patient'] for row in reader]\n",
    "with open('./csv/test.csv','r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    test_list = [row['patient'] for row in reader]\n",
    "\n",
    "dataset['outcome'] = pd.to_numeric(dataset['outcome'],errors='coerce')\n",
    "array_OG = dataset.values\n",
    "print(array_OG.shape)\n",
    "train_list = train_list[1:]\n",
    "validation_list = validation_list[0:]\n",
    "test_list = test_list[0:]\n",
    "#print(test_list)\n",
    "#print(train_list)\n",
    "#print(validation_list)\n",
    "\n",
    "def cat_str(num_list):\n",
    "    n_list = []\n",
    "    for i in num_list:\n",
    "        temp = i[12:]\n",
    "        n_list.append(temp)\n",
    "    n_list = [int(x) for x in n_list]\n",
    "    return n_list\n",
    "\n",
    "train_list = cat_str(train_list)\n",
    "validation_list = cat_str(validation_list)\n",
    "test_list = cat_str(test_list)\n",
    "\n",
    "#print(train_list)\n",
    "#print(validation_list)\n",
    "#print(test_list)\n",
    "#print(len(test_list))\n",
    "\n",
    "train_feature = []\n",
    "validate_feature = []\n",
    "test_feature = []\n",
    "count = 1\n",
    "for i in range(len(array_OG)):\n",
    "    num = i + 1\n",
    "    if num in train_list:\n",
    "        train_feature.append(array_OG[i])\n",
    "    elif num in validation_list:\n",
    "        validate_feature.append(array_OG[i])\n",
    "    elif num in test_list:\n",
    "        #print(count)\n",
    "        count = count + 1\n",
    "        test_feature.append(array_OG[i])\n",
    "        #print(num)\n",
    "        #print(array_OG[i,6096])\n",
    "        \n",
    "train_feature = np.array(train_feature)\n",
    "validate_feature = np.array(validate_feature)\n",
    "test_feature = np.array(test_feature)\n",
    "\n",
    "train_feature = pd.DataFrame(train_feature)\n",
    "train_feature.dropna(axis=1, thresh=2, inplace=True)\n",
    "train_feature.dropna(how='all',thresh = 20,inplace=True)\n",
    "train_feature = np.array(train_feature)\n",
    "wh_inf = np.isinf(train_feature)\n",
    "train_feature[wh_inf]=0\n",
    "wh_nan = np.isnan(train_feature)\n",
    "train_feature[wh_nan]=0\n",
    "\n",
    "validate_feature = pd.DataFrame(validate_feature)\n",
    "validate_feature.dropna(axis=1, thresh=2, inplace=True)\n",
    "#validate_feature.dropna(how='all',thresh = 20,inplace=True)\n",
    "validate_feature = np.array(validate_feature)\n",
    "wh_inf = np.isinf(validate_feature)\n",
    "validate_feature[wh_inf]=0\n",
    "wh_nan = np.isnan(validate_feature)\n",
    "validate_feature[wh_nan]=0\n",
    "\n",
    "test_feature = pd.DataFrame(test_feature)\n",
    "test_feature.dropna(axis=1, thresh=2, inplace=True)\n",
    "#test_feature.dropna(how='all',thresh = 20,inplace=True)\n",
    "test_feature = np.array(test_feature)\n",
    "wh_inf = np.isinf(test_feature)\n",
    "test_feature[wh_inf]=0\n",
    "wh_nan = np.isnan(test_feature)\n",
    "test_feature[wh_nan]=0\n",
    "\n",
    "#only use image features\n",
    "X_train = train_feature[:,:6093]\n",
    "Y_train = train_feature[:,6093]\n",
    "Y_train = Y_train.astype('int32')\n",
    "\n",
    "X_validate = validate_feature[:,:6093]\n",
    "Y_validate = validate_feature[:,6093]\n",
    "Y_validate = Y_validate.astype('int32')\n",
    "\n",
    "X_test = test_feature[:,:6093]\n",
    "Y_test = test_feature[:,6093]\n",
    "Y_test = Y_test.astype('int32')\n",
    "seed = 7\n",
    "\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(X_train) \n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(Y_train)\n",
    "\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=210, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.8339737636405852\n",
      "Generation 2 - Current best internal CV score: 0.8339737636405852\n",
      "Generation 3 - Current best internal CV score: 0.8339737636405852\n",
      "Generation 4 - Current best internal CV score: 0.8362630601346644\n",
      "Generation 5 - Current best internal CV score: 0.8378306632613576\n",
      "Generation 6 - Current best internal CV score: 0.8378306632613576\n",
      "Generation 7 - Current best internal CV score: 0.8378306632613576\n",
      "Generation 8 - Current best internal CV score: 0.8378306632613576\n",
      "Generation 9 - Current best internal CV score: 0.8391865954647473\n",
      "Generation 10 - Current best internal CV score: 0.8393994272889096\n",
      "Generation 11 - Current best internal CV score: 0.8393994272889096\n",
      "Generation 12 - Current best internal CV score: 0.8393994272889096\n",
      "Generation 13 - Current best internal CV score: 0.8393994272889096\n",
      "Generation 14 - Current best internal CV score: 0.8393994272889096\n",
      "Generation 15 - Current best internal CV score: 0.8393994272889096\n",
      "Generation 16 - Current best internal CV score: 0.8393994272889096\n",
      "Generation 17 - Current best internal CV score: 0.8393994272889096\n",
      "Generation 18 - Current best internal CV score: 0.8393994272889096\n",
      "Generation 19 - Current best internal CV score: 0.8393994272889096\n",
      "Generation 20 - Current best internal CV score: 0.8401795526662024\n",
      "\n",
      "Best pipeline: DecisionTreeClassifier(CombineDFs(SelectPercentile(input_matrix, percentile=30), input_matrix), criterion=gini, max_depth=4, min_samples_leaf=16, min_samples_split=2)\n",
      "Accuracy: 0.7590361445783133\n",
      "Average Precision Score: 0.6779033426940846\n",
      "Kappa: 0.5044776119402985\n",
      "Hamming Loss: 0.24096385542168675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrisonbai/miniconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_prob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3b435c0b0358>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Kappa: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcohen_kappa_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred_vali\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hamming Loss: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhamming_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred_vali\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AUC: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AUC: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AUC: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred_vali\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_prob' is not defined"
     ]
    }
   ],
   "source": [
    "#直接运行Tpot\n",
    "pipeline_optimizer = TPOTClassifier(generations=20, population_size=10, config_dict = 'TPOT light',cv=5, verbosity=2, scoring='roc_auc')\n",
    "pipeline_optimizer.fit(X_train,Y_train)\n",
    "joblib.dump(pipeline_optimizer.fitted_pipeline_,'./pkl/tpot_running_11.pkl')\n",
    "pipeline_optimizer.export('./py/tpot_running_11.py')\n",
    "\n",
    "Y_pred_vali = pipeline_optimizer.predict(X_validate)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_validate, Y_pred_vali)))\n",
    "\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Sensitivity: \" + repr(recall_score(Y_validate, Y_pred_vali)))\n",
    "tn, fp, fn, tp = confusion_matrix(Y_validate, Y_pred_vali).ravel()\n",
    "print(\"Specificity: \" + repr(tn / (tn + fp)))\n",
    "\n",
    "Y_pred = pipeline_optimizer.predict(X_test)\n",
    "Y_prob = pipeline_optimizer.predict_proba(X_test)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_test, Y_pred)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_test, Y_pred)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_test, Y_pred)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_test, Y_pred)))\n",
    "y_prob = np.empty((len(Y_prob),1))\n",
    "for i in range(len(Y_prob)):\n",
    "    #print(i)\n",
    "    y_prob[i] = Y_prob[i][1]\n",
    "    #print(y_prob[i][0])\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_test, y_prob)))\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_test, Y_pred)))\n",
    "print(\"Sensitivity: \" + repr(recall_score(Y_test, Y_pred)))\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, Y_pred).ravel()\n",
    "print(\"Specificity: \" + repr(tn / (tn + fp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7470760233918128\n",
      "Sensitivity: 0.6052631578947368\n",
      "Specificity: 0.8888888888888888\n",
      "Accuracy: 0.7349397590361446\n",
      "Average Precision Score: 0.6387303600366377\n",
      "Kappa: 0.46388725778038753\n",
      "Hamming Loss: 0.26506024096385544\n",
      "AUC: 0.802046783625731\n",
      "AUC: 0.7309941520467835\n",
      "Sensitivity: 0.6842105263157895\n",
      "Specificity: 0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrisonbai/miniconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/Users/harrisonbai/miniconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC: \" + repr(roc_auc_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Sensitivity: \" + repr(recall_score(Y_validate, Y_pred_vali)))\n",
    "tn, fp, fn, tp = confusion_matrix(Y_validate, Y_pred_vali).ravel()\n",
    "print(\"Specificity: \" + repr(tn / (tn + fp)))\n",
    "\n",
    "Y_pred = pipeline_optimizer.predict(X_test)\n",
    "Y_prob = pipeline_optimizer.predict_proba(X_test)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_test, Y_pred)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_test, Y_pred)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_test, Y_pred)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_test, Y_pred)))\n",
    "y_prob = np.empty((len(Y_prob),1))\n",
    "for i in range(len(Y_prob)):\n",
    "    #print(i)\n",
    "    y_prob[i] = Y_prob[i][1]\n",
    "    #print(y_prob[i][0])\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_test, y_prob)))\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_test, Y_pred)))\n",
    "print(\"Sensitivity: \" + repr(recall_score(Y_test, Y_pred)))\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, Y_pred).ravel()\n",
    "print(\"Specificity: \" + repr(tn / (tn + fp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=210, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.836349547248665\n",
      "Generation 2 - Current best internal CV score: 0.836349547248665\n",
      "Generation 3 - Current best internal CV score: 0.836349547248665\n",
      "Generation 4 - Current best internal CV score: 0.836349547248665\n",
      "Generation 5 - Current best internal CV score: 0.8373781054097981\n",
      "Generation 6 - Current best internal CV score: 0.8373781054097981\n",
      "Generation 7 - Current best internal CV score: 0.8373781054097981\n",
      "Generation 8 - Current best internal CV score: 0.8373781054097981\n",
      "Generation 9 - Current best internal CV score: 0.8373781054097981\n",
      "Generation 10 - Current best internal CV score: 0.8373781054097981\n",
      "Generation 11 - Current best internal CV score: 0.8383481025720403\n",
      "Generation 12 - Current best internal CV score: 0.8383481025720403\n",
      "Generation 13 - Current best internal CV score: 0.8383481025720403\n",
      "Generation 14 - Current best internal CV score: 0.8383481025720403\n",
      "Generation 15 - Current best internal CV score: 0.8383481025720403\n",
      "Generation 16 - Current best internal CV score: 0.8397231251451126\n",
      "Generation 17 - Current best internal CV score: 0.8397231251451126\n",
      "Generation 18 - Current best internal CV score: 0.8397231251451126\n",
      "Generation 19 - Current best internal CV score: 0.8397231251451126\n",
      "Generation 20 - Current best internal CV score: 0.8401049325387613\n",
      "\n",
      "Best pipeline: DecisionTreeClassifier(CombineDFs(input_matrix, input_matrix), criterion=gini, max_depth=4, min_samples_leaf=20, min_samples_split=10)\n",
      "Accuracy: 0.8072289156626506\n",
      "Average Precision Score: 0.7196542402296165\n",
      "Kappa: 0.6116959064327485\n",
      "Hamming Loss: 0.1927710843373494\n",
      "AUC: 0.8058479532163743\n",
      "Sensitivity: 0.7894736842105263\n",
      "Specificity: 0.8222222222222222\n",
      "Accuracy: 0.7469879518072289\n",
      "Average Precision Score: 0.6482283434121595\n",
      "Kappa: 0.4934612031386225\n",
      "Hamming Loss: 0.25301204819277107\n",
      "AUC: 0.7809941520467836\n",
      "AUC: 0.7482456140350877\n",
      "Sensitivity: 0.7631578947368421\n",
      "Specificity: 0.7333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrisonbai/miniconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/Users/harrisonbai/miniconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/Users/harrisonbai/miniconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/Users/harrisonbai/miniconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/Users/harrisonbai/miniconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/Users/harrisonbai/miniconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#直接运行Tpot\n",
    "pipeline_optimizer = TPOTClassifier(generations=20, population_size=10, config_dict = 'TPOT light',cv=5, verbosity=2, scoring='roc_auc')\n",
    "pipeline_optimizer.fit(X_train,Y_train)\n",
    "joblib.dump(pipeline_optimizer.fitted_pipeline_,'./pkl/tpot_running_10.pkl')\n",
    "pipeline_optimizer.export('./py/tpot_running_10.py')\n",
    "\n",
    "Y_pred_vali = pipeline_optimizer.predict(X_validate)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_validate, Y_pred_vali)))\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Sensitivity: \" + repr(recall_score(Y_validate, Y_pred_vali)))\n",
    "tn, fp, fn, tp = confusion_matrix(Y_validate, Y_pred_vali).ravel()\n",
    "print(\"Specificity: \" + repr(tn / (tn + fp)))\n",
    "\n",
    "Y_pred = pipeline_optimizer.predict(X_test)\n",
    "Y_prob = pipeline_optimizer.predict_proba(X_test)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_test, Y_pred)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_test, Y_pred)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_test, Y_pred)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_test, Y_pred)))\n",
    "y_prob = np.empty((len(Y_prob),1))\n",
    "for i in range(len(Y_prob)):\n",
    "    #print(i)\n",
    "    y_prob[i] = Y_prob[i][1]\n",
    "    #print(y_prob[i][0])\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_test, y_prob)))\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_test, Y_pred)))\n",
    "print(\"Sensitivity: \" + repr(recall_score(Y_test, Y_pred)))\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, Y_pred).ravel()\n",
    "print(\"Specificity: \" + repr(tn / (tn + fp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8072289156626506\n",
      "Average Precision Score: 0.7196542402296165\n",
      "Kappa: 0.6116959064327485\n",
      "Hamming Loss: 0.1927710843373494\n",
      "AUC: 0.8058479532163743\n",
      "Sensitivity: 0.7894736842105263\n",
      "Specificity: 0.8222222222222222\n",
      "###################\n",
      "Accuracy: 0.7951807228915663\n",
      "Average Precision Score: 0.7065845173010677\n",
      "Kappa: 0.586580720773513\n",
      "Hamming Loss: 0.20481927710843373\n",
      "AUC: 0.7926900584795322\n",
      "Sensitivity: 0.7631578947368421\n",
      "Specificity: 0.8222222222222222\n",
      "###################\n",
      "Accuracy: 0.8072289156626506\n",
      "Average Precision Score: 0.7196542402296165\n",
      "Kappa: 0.6116959064327485\n",
      "Hamming Loss: 0.1927710843373494\n",
      "AUC: 0.8058479532163743\n",
      "Sensitivity: 0.7894736842105263\n",
      "Specificity: 0.8222222222222222\n",
      "###################\n",
      "Accuracy: 0.8433734939759037\n",
      "Average Precision Score: 0.7632473212688812\n",
      "Kappa: 0.6851473592063029\n",
      "Hamming Loss: 0.1566265060240964\n",
      "AUC: 0.8432748538011696\n",
      "Sensitivity: 0.8421052631578947\n",
      "Specificity: 0.8444444444444444\n",
      "###################\n",
      "Accuracy: 0.8072289156626506\n",
      "Average Precision Score: 0.7196542402296165\n",
      "Kappa: 0.6116959064327485\n",
      "Hamming Loss: 0.1927710843373494\n",
      "AUC: 0.8058479532163743\n",
      "Sensitivity: 0.7894736842105263\n",
      "Specificity: 0.8222222222222222\n",
      "###################\n",
      "Accuracy: 0.7590361445783133\n",
      "Average Precision Score: 0.6779033426940846\n",
      "Kappa: 0.5044776119402985\n",
      "Hamming Loss: 0.24096385542168675\n",
      "AUC: 0.7470760233918128\n",
      "Sensitivity: 0.6052631578947368\n",
      "Specificity: 0.8888888888888888\n",
      "###################\n",
      "Accuracy: 0.7590361445783133\n",
      "Average Precision Score: 0.6779033426940846\n",
      "Kappa: 0.5044776119402985\n",
      "Hamming Loss: 0.24096385542168675\n",
      "AUC: 0.7470760233918128\n",
      "Sensitivity: 0.6052631578947368\n",
      "Specificity: 0.8888888888888888\n",
      "###################\n",
      "Accuracy: 0.8072289156626506\n",
      "Average Precision Score: 0.7196542402296165\n",
      "Kappa: 0.6116959064327485\n",
      "Hamming Loss: 0.1927710843373494\n",
      "AUC: 0.8058479532163743\n",
      "Sensitivity: 0.7894736842105263\n",
      "Specificity: 0.8222222222222222\n",
      "###################\n",
      "Accuracy: 0.8072289156626506\n",
      "Average Precision Score: 0.7196542402296165\n",
      "Kappa: 0.6116959064327485\n",
      "Hamming Loss: 0.1927710843373494\n",
      "AUC: 0.8058479532163743\n",
      "Sensitivity: 0.7894736842105263\n",
      "Specificity: 0.8222222222222222\n",
      "###################\n",
      "Accuracy: 0.7590361445783133\n",
      "Average Precision Score: 0.6779033426940846\n",
      "Kappa: 0.5044776119402985\n",
      "Hamming Loss: 0.24096385542168675\n",
      "AUC: 0.7470760233918128\n",
      "Sensitivity: 0.6052631578947368\n",
      "Specificity: 0.8888888888888888\n",
      "Accuracy: 0.7951807228915663\n",
      "Average Precision Score: 0.7065845173010677\n",
      "Kappa: 0.586580720773513\n",
      "Hamming Loss: 0.20481927710843373\n",
      "AUC: 0.8906432748538011\n",
      "AUC: 0.7926900584795322\n",
      "Sensitivity: 0.7631578947368421\n",
      "Specificity: 0.8222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrisonbai/miniconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/Users/harrisonbai/miniconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/Users/harrisonbai/miniconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/Users/harrisonbai/miniconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/Users/harrisonbai/miniconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/Users/harrisonbai/miniconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/Users/harrisonbai/miniconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#load tpot run\n",
    "model1 = joblib.load('./pkl/tpot_running_2.pkl')\n",
    "model2 = joblib.load('./pkl/tpot_running_3.pkl')\n",
    "model3 = joblib.load('./pkl/tpot_running_4.pkl')\n",
    "model4 = joblib.load('./pkl/tpot_running_5.pkl')\n",
    "model5 = joblib.load('./pkl/tpot_running_6.pkl')\n",
    "model6 = joblib.load('./pkl/tpot_running_7.pkl')\n",
    "model7 = joblib.load('./pkl/tpot_running_8.pkl')\n",
    "model8 = joblib.load('./pkl/tpot_running_9.pkl')\n",
    "model9 = joblib.load('./pkl/tpot_running_10.pkl')\n",
    "model10 = joblib.load('./pkl/tpot_running_11.pkl')\n",
    "\n",
    "\n",
    "#validation predict \n",
    "Y_pred_vali = model1.predict(X_validate)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_validate, Y_pred_vali)))\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Sensitivity: \" + repr(recall_score(Y_validate, Y_pred_vali)))\n",
    "tn, fp, fn, tp = confusion_matrix(Y_validate, Y_pred_vali).ravel()\n",
    "print(\"Specificity: \" + repr(tn / (tn + fp)))\n",
    "\n",
    "print(\"###################\")\n",
    "Y_pred_vali = model2.predict(X_validate)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_validate, Y_pred_vali)))\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Sensitivity: \" + repr(recall_score(Y_validate, Y_pred_vali)))\n",
    "tn, fp, fn, tp = confusion_matrix(Y_validate, Y_pred_vali).ravel()\n",
    "print(\"Specificity: \" + repr(tn / (tn + fp)))\n",
    "\n",
    "print(\"###################\")\n",
    "Y_pred_vali = model3.predict(X_validate)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_validate, Y_pred_vali)))\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Sensitivity: \" + repr(recall_score(Y_validate, Y_pred_vali)))\n",
    "tn, fp, fn, tp = confusion_matrix(Y_validate, Y_pred_vali).ravel()\n",
    "print(\"Specificity: \" + repr(tn / (tn + fp)))\n",
    "\n",
    "print(\"###################\")\n",
    "Y_pred_vali = model4.predict(X_validate)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_validate, Y_pred_vali)))\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Sensitivity: \" + repr(recall_score(Y_validate, Y_pred_vali)))\n",
    "tn, fp, fn, tp = confusion_matrix(Y_validate, Y_pred_vali).ravel()\n",
    "print(\"Specificity: \" + repr(tn / (tn + fp)))\n",
    "\n",
    "print(\"###################\")\n",
    "Y_pred_vali = model5.predict(X_validate)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_validate, Y_pred_vali)))\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Sensitivity: \" + repr(recall_score(Y_validate, Y_pred_vali)))\n",
    "tn, fp, fn, tp = confusion_matrix(Y_validate, Y_pred_vali).ravel()\n",
    "print(\"Specificity: \" + repr(tn / (tn + fp)))\n",
    "\n",
    "print(\"###################\")\n",
    "Y_pred_vali = model6.predict(X_validate)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_validate, Y_pred_vali)))\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Sensitivity: \" + repr(recall_score(Y_validate, Y_pred_vali)))\n",
    "tn, fp, fn, tp = confusion_matrix(Y_validate, Y_pred_vali).ravel()\n",
    "print(\"Specificity: \" + repr(tn / (tn + fp)))\n",
    "\n",
    "print(\"###################\")\n",
    "Y_pred_vali = model7.predict(X_validate)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_validate, Y_pred_vali)))\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Sensitivity: \" + repr(recall_score(Y_validate, Y_pred_vali)))\n",
    "tn, fp, fn, tp = confusion_matrix(Y_validate, Y_pred_vali).ravel()\n",
    "print(\"Specificity: \" + repr(tn / (tn + fp)))\n",
    "\n",
    "print(\"###################\")\n",
    "Y_pred_vali = model8.predict(X_validate)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_validate, Y_pred_vali)))\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Sensitivity: \" + repr(recall_score(Y_validate, Y_pred_vali)))\n",
    "tn, fp, fn, tp = confusion_matrix(Y_validate, Y_pred_vali).ravel()\n",
    "print(\"Specificity: \" + repr(tn / (tn + fp)))\n",
    "\n",
    "print(\"###################\")\n",
    "Y_pred_vali = model9.predict(X_validate)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_validate, Y_pred_vali)))\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Sensitivity: \" + repr(recall_score(Y_validate, Y_pred_vali)))\n",
    "tn, fp, fn, tp = confusion_matrix(Y_validate, Y_pred_vali).ravel()\n",
    "print(\"Specificity: \" + repr(tn / (tn + fp)))\n",
    "\n",
    "print(\"###################\")\n",
    "Y_pred_vali = model10.predict(X_validate)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_validate, Y_pred_vali)))\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_validate, Y_pred_vali)))\n",
    "print(\"Sensitivity: \" + repr(recall_score(Y_validate, Y_pred_vali)))\n",
    "tn, fp, fn, tp = confusion_matrix(Y_validate, Y_pred_vali).ravel()\n",
    "print(\"Specificity: \" + repr(tn / (tn + fp)))\n",
    "\n",
    "\n",
    "Y_pred = model4.predict(X_test)\n",
    "Y_prob = model4.predict_proba(X_test)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_test, Y_pred)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_test, Y_pred)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_test, Y_pred)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_test, Y_pred)))\n",
    "y_prob = np.empty((len(Y_prob),1))\n",
    "for i in range(len(Y_prob)):\n",
    "    #print(i)\n",
    "    y_prob[i] = Y_prob[i][1]\n",
    "    #print(y_prob[i][0])\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_test, y_prob)))\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_test, Y_pred)))\n",
    "print(\"Sensitivity: \" + repr(recall_score(Y_test, Y_pred)))\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, Y_pred).ravel()\n",
    "print(\"Specificity: \" + repr(tn / (tn + fp)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7951807228915663\n",
      "Average Precision Score: 0.7065845173010677\n",
      "Kappa: 0.586580720773513\n",
      "Hamming Loss: 0.20481927710843373\n",
      "AUC: 0.8906432748538011\n",
      "Sensitivity: 0.7631578947368421\n",
      "Specificity: 0.8222222222222222\n"
     ]
    }
   ],
   "source": [
    "model4 = joblib.load('./pkl/tpot_running_5.pkl')\n",
    "Y_pred = model4.predict(X_test)\n",
    "Y_prob = model4.predict_proba(X_test)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_test, Y_pred)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_test, Y_pred)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_test, Y_pred)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_test, Y_pred)))\n",
    "y_prob = np.empty((len(Y_prob),1))\n",
    "for i in range(len(Y_prob)):\n",
    "    #print(i)\n",
    "    y_prob[i] = Y_prob[i][1]\n",
    "    #print(y_prob[i][0])\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_test, y_prob)))\n",
    "#print(\"AUC: \" + repr(roc_auc_score(Y_test, Y_pred)))\n",
    "print(\"Sensitivity: \" + repr(recall_score(Y_test, Y_pred)))\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, Y_pred).ravel()\n",
    "print(\"Specificity: \" + repr(tn / (tn + fp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6413871248108438\n",
      "0.590864652662682\n",
      "0.7409354314943646\n",
      "0.8378609128202502\n",
      "0.8449068629679674\n",
      "0.7737881634286459\n",
      "0.8782377777568229\n",
      "0.7536356434211773\n",
      "0.8213248497166938\n",
      "0.706109208277325\n",
      "0.3716000860783897\n",
      "0.3942728196808361\n",
      "0.8905333747295947\n",
      "0.7863843702714586\n",
      "0.8160368095194575\n",
      "0.7308174466456937\n",
      "0.7474938462650705\n",
      "0.778349717222842\n",
      "0.5758228810618466\n",
      "0.4340065644131185\n",
      "0.9643080621715757\n",
      "0.7666178922480512\n",
      "0.7988493977224763\n",
      "0.23734994612813082\n",
      "0.45017463892403264\n",
      "0.2094900571571396\n",
      "0.7323958164966722\n",
      "0.8613404707563439\n",
      "0.20263105224139039\n",
      "0.7720464218904775\n",
      "0.008423722476354055\n",
      "0.4069409031191069\n",
      "0.18237521862320955\n",
      "0.6412766276566372\n",
      "0.16902152539191218\n",
      "0.030171695864738782\n",
      "0.3651138450282872\n",
      "0.2107769719745521\n",
      "0.22789403398365088\n",
      "0.3372213504473148\n",
      "0.6588533827254559\n",
      "0.14778832417316093\n",
      "0.09326799526651461\n",
      "0.0727619357745986\n",
      "0.08129939993417994\n",
      "0.33454236462289527\n",
      "0.3533995209500532\n",
      "0.3310076526299381\n",
      "0.6429757163360358\n",
      "0.06221813084241434\n",
      "0.4291254220970403\n",
      "0.13917416412913705\n",
      "0.21054692938647185\n",
      "0.037484121469247324\n",
      "0.11626486995481944\n",
      "0.09928522216165399\n",
      "0.36978903050996387\n",
      "0.6747511266793079\n",
      "0.4332478343381983\n",
      "0.7707778654196455\n",
      "0.8224326161018989\n",
      "0.858232456945109\n",
      "0.2442598073416803\n",
      "0.22371660718603648\n",
      "0.1321645448425767\n",
      "0.18129654324914152\n",
      "0.08385123344273969\n",
      "0.2336725457041483\n",
      "0.6440046893497703\n",
      "0.5167735361042249\n",
      "0.3320941648944454\n",
      "0.02576212250791504\n",
      "0.1694622751181612\n",
      "0.18681622543406795\n",
      "0.7429910794281173\n",
      "0.2516111592431397\n",
      "0.8293094383804255\n",
      "0.057831899236082805\n",
      "0.5920447015639885\n",
      "0.40828870607319173\n",
      "0.16424827538812978\n",
      "0.8366007368967161\n",
      "0.8794623636371717\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_prob)):\n",
    "    print(y_prob[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 8 9 29\n",
      "(0.70-0.87)\n",
      "(0.60-0.87)\n",
      "(0.68-0.91)\n"
     ]
    }
   ],
   "source": [
    "print(tn,fp,fn,tp)\n",
    "import sys\n",
    "#p is proportion of trials that were successes\n",
    "#n is the number of trials\n",
    "import math\n",
    "def adjusted_wald(p, n, z=1.96):\n",
    "    p_adj = (n * p + (z**2)/2)/(n+z**2)\n",
    "    n_adj = n + z**2\n",
    "    span = z * math.sqrt(p_adj*(1-p_adj)/n_adj)\n",
    "    return max(0, p_adj - span), min(p_adj + span, 1.0)\n",
    "print(\"({:.2f}-{:.2f})\".format(*adjusted_wald(float(0.80), float(83))))\n",
    "print(\"({:.2f}-{:.2f})\".format(*adjusted_wald(float(0.76), float(38))))\n",
    "print(\"({:.2f}-{:.2f})\".format(*adjusted_wald(float(0.82), float(45))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
