{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           radVar1   radVar2       radVar3   radVar4   radVar5   radVar6  \\\n",
      "0      9798.333333   10056.0   4605.342618  0.470013  0.017688  0.111166   \n",
      "1     15741.000000   16040.0   5913.624260  0.375683  0.019529  0.135505   \n",
      "2      8414.333333    8576.0   3127.396302  0.371675  0.027144  0.261784   \n",
      "3      3880.000000    4040.0   2114.539901  0.544985  0.022513  0.180081   \n",
      "4     11004.333330   11288.0   4994.883375  0.453901  0.017587  0.109902   \n",
      "5     17986.000000   18216.0   5194.529575  0.288810  0.027104  0.261025   \n",
      "6      4250.000000    4424.0   2565.628846  0.603677  0.018451  0.120962   \n",
      "7       220.666667     304.0    375.346874  1.700968  0.017120  0.104142   \n",
      "8      1958.000000    2080.0   1274.102930  0.650717  0.024290  0.209635   \n",
      "9     93042.333330   93344.0  13220.881980  0.142095  0.034531  0.423674   \n",
      "10     4437.000000    4584.0   1952.664949  0.440087  0.029012  0.299053   \n",
      "11     2104.666667    2224.0   1410.781996  0.670311  0.022409  0.178418   \n",
      "12    23736.666670   24000.0   8192.717965  0.345150  0.018059  0.115880   \n",
      "13      561.666667     616.0    418.410786  0.744945  0.037025  0.487081   \n",
      "14    21002.333330   21352.0   7227.452030  0.344126  0.019285  0.132139   \n",
      "15     9555.333333    9728.0   3803.200143  0.398019  0.022985  0.187714   \n",
      "16     7602.666667    7760.0   2930.744098  0.385489  0.027035  0.259687   \n",
      "17   863343.000000  864096.0  71226.781510  0.082501  0.025624  0.233286   \n",
      "20      519.333333     584.0    440.973075  0.849114  0.031641  0.355720   \n",
      "21    16067.666670   16568.0   8288.083369  0.515824  0.012014  0.051286   \n",
      "22    13031.666670   13352.0   5583.558384  0.428461  0.017622  0.110336   \n",
      "23    53219.000000   53528.0  12193.706270  0.229123  0.022299  0.176676   \n",
      "24     1971.666667    2064.0   1097.686534  0.556730  0.030587  0.332418   \n",
      "25     3024.000000    3120.0   1364.110270  0.451095  0.033864  0.407444   \n",
      "26     7730.666667    7872.0   2783.262373  0.360029  0.029704  0.313490   \n",
      "27     2993.333333    3120.0   1514.054637  0.505809  0.028666  0.291970   \n",
      "28     2206.000000    2352.0   1478.250924  0.670105  0.021898  0.170380   \n",
      "29    53677.000000   54168.0  15074.458820  0.280836  0.016363  0.095127   \n",
      "30     7608.333333    7744.0   2623.513972  0.344821  0.031944  0.362561   \n",
      "31   189437.333300  190176.0  29735.563720  0.156968  0.020844  0.154367   \n",
      "..             ...       ...           ...       ...       ...       ...   \n",
      "715    6542.666667    6832.0   3719.867625  0.568555  0.016270  0.094054   \n",
      "716    4089.333333    4320.0   2576.412294  0.630032  0.017642  0.110589   \n",
      "717   14086.333330   14256.0   3914.373518  0.277884  0.032451  0.374164   \n",
      "718    2159.666667    2280.0   1529.937143  0.708414  0.020361  0.147301   \n",
      "719     876.666667     960.0    716.271724  0.817040  0.025801  0.236531   \n",
      "720   13287.666670   13480.0   4027.468238  0.303098  0.029331  0.305670   \n",
      "721    4481.333333    4696.0   2589.569457  0.577857  0.019186  0.130793   \n",
      "722     575.666667     712.0    740.885036  1.287004  0.016105  0.092160   \n",
      "723   29510.666670   29784.0   6819.702629  0.231093  0.029564  0.310538   \n",
      "724    1020.666667    1096.0    736.651899  0.721736  0.028802  0.294736   \n",
      "725     639.333333     752.0    698.581780  1.092672  0.019536  0.135599   \n",
      "727    6402.333333    6552.0   2484.189355  0.388013  0.029173  0.302395   \n",
      "728    2049.333333    2160.0   1320.233771  0.644226  0.024102  0.206407   \n",
      "730     840.000000     992.0    955.729199  1.137773  0.016040  0.091413   \n",
      "731     173.333333     304.0    364.928026  2.105354  0.014028  0.069919   \n",
      "732   33253.666670   33632.0   9510.882650  0.286010  0.020227  0.145368   \n",
      "733    3361.666667    3552.0   2233.680754  0.664456  0.017966  0.114683   \n",
      "734   11253.333330   11440.0   3972.270518  0.352986  0.025360  0.228506   \n",
      "735    4957.666667    5240.0   2967.862852  0.598641  0.017300  0.106335   \n",
      "736    1296.666667    1472.0   1320.658906  1.018503  0.015243  0.082554   \n",
      "737   26517.000000   26728.0   5869.528582  0.221350  0.033269  0.393271   \n",
      "739    4437.333333    4624.0   2257.414251  0.508732  0.023342  0.193581   \n",
      "740    6163.333333    6368.0   2907.513359  0.471744  0.022180  0.174791   \n",
      "741    3252.666667    3416.0   1984.775374  0.610199  0.020754  0.153037   \n",
      "742   12881.666670   13088.0   4243.433030  0.329416  0.026292  0.245609   \n",
      "744   11273.000000   11496.0   4207.823208  0.373266  0.023301  0.192912   \n",
      "745    9676.333333    9824.0   3015.638501  0.311651  0.032966  0.386132   \n",
      "746    4038.666667    4248.0   2638.384750  0.653281  0.016813  0.100442   \n",
      "748    8400.333333    8616.0   3745.856145  0.445918  0.020673  0.151842   \n",
      "749     444.000000     520.0    476.796266  1.073865  0.024061  0.205693   \n",
      "\n",
      "      radVar7   radVar8   radVar9  radVar10  ...    radVar6087   radVar6088  \\\n",
      "0    2.079743  0.480829  1.079743  0.301527  ...   5979.230769   131.000000   \n",
      "1    1.946920  0.513632  0.946920  0.572136  ...   5159.036437   123.955466   \n",
      "2    1.563216  0.639707  0.563216  0.802413  ...   5901.125000    80.000000   \n",
      "3    1.770832  0.564706  0.770832  0.450859  ...   7123.164179    67.000000   \n",
      "4    2.087687  0.478999  1.087687  0.323703  ...   3174.323529    92.952941   \n",
      "5    1.564729  0.639088  0.564729  0.510173  ...  11373.627990   214.078498   \n",
      "6    2.022012  0.494557  1.022012  1.052474  ...   2727.508772    38.052632   \n",
      "7    2.125482  0.470481  1.125482  0.676375  ...    334.285714     7.000000   \n",
      "8    1.683366  0.594048  0.683366  0.482685  ...   2993.500000    28.250000   \n",
      "9    1.331443  0.751065  0.331443  3.081852  ...  10184.815610   953.067680   \n",
      "10   1.495377  0.668728  0.495377  0.627650  ...   5268.285714    45.314286   \n",
      "11   1.776316  0.562963  0.776316  0.158363  ...   7287.840000    50.000000   \n",
      "12   2.051150  0.487531  1.051150  0.350237  ...   5131.866120   191.743169   \n",
      "13   1.270963  0.786805  0.270963  0.125625  ...   2420.000000     9.000000   \n",
      "14   1.963312  0.509343  0.963312  1.557697  ...    598.919753    67.481481   \n",
      "15   1.746497  0.572575  0.746497  0.310552  ...   4957.835366    89.621951   \n",
      "16   1.567412  0.637994  0.567412  0.404637  ...  10586.473280   131.000000   \n",
      "17   1.624440  0.615597  0.624440  3.335111  ...   1326.736952  1921.283020   \n",
      "20   1.411336  0.708548  0.411336  0.160712  ...    540.000000     5.000000   \n",
      "21   2.691544  0.371534  1.691544  2.904391  ...   6480.720833   180.208333   \n",
      "22   2.084940  0.479630  1.084940  2.259410  ...   6549.290909   180.400000   \n",
      "23   1.782134  0.561125  0.782134  0.781334  ...   6860.048135   425.825511   \n",
      "24   1.443572  0.692726  0.443572  1.141310  ...   2679.242424    21.969697   \n",
      "25   1.348893  0.741349  0.348893  0.204599  ...   7526.769231    52.000000   \n",
      "26   1.472060  0.679320  0.472060  0.476635  ...   6649.106061    92.727273   \n",
      "27   1.507373  0.663406  0.507373  2.168606  ...   1886.240000    29.320000   \n",
      "28   1.803822  0.554378  0.803822  0.143541  ...   3157.297297    37.000000   \n",
      "29   2.190612  0.456493  1.190612  3.813238  ...   2822.142509   180.232643   \n",
      "30   1.402403  0.713062  0.402403  0.261621  ...   9280.220339   106.610170   \n",
      "31   1.864154  0.536437  0.864154  2.706557  ...  10326.147990  1824.917450   \n",
      "..        ...       ...       ...       ...  ...           ...          ...   \n",
      "715  2.198907  0.454771  1.198907  1.704183  ...   2101.646465    59.727273   \n",
      "716  2.083353  0.479995  1.083353  0.649159  ...   5073.714286    63.000000   \n",
      "717  1.387755  0.720588  0.387755  0.262989  ...  10202.995590   166.418502   \n",
      "718  1.893499  0.528123  0.893499  0.972465  ...   2851.200000    40.000000   \n",
      "719  1.616978  0.618438  0.616978  0.109351  ...    954.312500     9.125000   \n",
      "720  1.484507  0.673624  0.484507  0.707451  ...   6723.449275   120.140097   \n",
      "721  1.970026  0.507608  0.970026  1.935610  ...   2858.460674    45.449438   \n",
      "722  2.213873  0.451697  1.213873  0.189972  ...    546.545455    11.000000   \n",
      "723  1.476710  0.677181  0.476710  0.987288  ...  10596.731760   307.781116   \n",
      "724  1.502642  0.665494  0.502642  0.336987  ...   2559.789474    19.000000   \n",
      "725  1.946472  0.513750  0.946472  0.117606  ...    816.090909     9.181818   \n",
      "727  1.489847  0.671210  0.489847  0.047397  ...   9471.364486   107.000000   \n",
      "728  1.692096  0.590983  0.692096  0.310212  ...   3591.210526    34.210526   \n",
      "730  2.219889  0.450473  1.219889  0.944686  ...    872.235294    12.058824   \n",
      "731  2.427365  0.411969  1.427365  0.853423  ...    108.000000     3.000000   \n",
      "732  1.901853  0.525803  0.901853  2.255384  ...   9528.186180   360.623800   \n",
      "733  2.058261  0.485847  1.058261  0.456195  ...   1726.813559    31.406780   \n",
      "734  1.635688  0.611363  0.635688  0.603304  ...   5190.303867   106.038674   \n",
      "735  2.110773  0.473760  1.110773  0.467240  ...   4450.280899    66.797753   \n",
      "736  2.296612  0.435424  1.296612  0.683217  ...   1257.120000    25.000000   \n",
      "737  1.364906  0.732651  0.364906  0.734135  ...   8700.713942   229.581731   \n",
      "739  1.728671  0.578479  0.728671  0.201258  ...   6979.436620    71.000000   \n",
      "740  1.788520  0.559121  0.788520  0.462090  ...   5766.264151    87.886792   \n",
      "741  1.869538  0.534892  0.869538  0.327182  ...   3445.333333    54.000000   \n",
      "742  1.596805  0.626251  0.596805  1.365487  ...  10674.004930   189.482759   \n",
      "744  1.730668  0.577812  0.730668  0.676271  ...   4915.711111    90.044444   \n",
      "745  1.373266  0.728191  0.373266  0.176132  ...   6499.019231    87.346154   \n",
      "746  2.151272  0.464841  1.151272  1.680439  ...   2610.069444    44.027778   \n",
      "748  1.874430  0.533495  0.874430  1.106710  ...   8280.514286   140.000000   \n",
      "749  1.694052  0.590301  0.694052  0.374023  ...   1404.000000    11.000000   \n",
      "\n",
      "     radVar6089   radVar6090  radVar6091    radVar6092  radVar6093  \\\n",
      "0      0.719780    10.208791    0.056092  1.474460e-01   28.292356   \n",
      "1      0.501844    14.821862    0.060008  2.490780e-01   27.717517   \n",
      "2      0.555556    11.097222    0.077064  2.222222e-01   15.157215   \n",
      "3      1.000000     5.149254    0.076855  0.000000e+00   19.423925   \n",
      "4      0.546782    13.517647    0.079516  2.266090e-01   13.997370   \n",
      "5      0.730643    12.959044    0.044229  1.346783e-01   53.953337   \n",
      "6      0.667590     6.122807    0.107418  1.662050e-01   17.930440   \n",
      "7      1.000000     3.857143    0.551020  7.890000e-31    0.285714   \n",
      "8      0.882812     4.125000    0.128906  5.859375e-02   10.812500   \n",
      "9      0.658196    67.459945    0.046588  1.872076e-01   37.917972   \n",
      "10     0.647347     4.885714    0.069796  1.763265e-01   33.011429   \n",
      "11     1.000000     4.400000    0.088000  7.890000e-31   19.649600   \n",
      "12     0.523888    22.431694    0.061289  2.380558e-01   21.980531   \n",
      "13     1.000000     3.666667    0.407407  0.000000e+00    1.432099   \n",
      "14     0.208276    33.790123    0.104291  1.683890e+00    7.778997   \n",
      "15     0.546475    10.243902    0.062463  2.267623e-01   24.832689   \n",
      "16     1.000000     7.549618    0.057631  7.890000e-31   29.447701   \n",
      "17     0.142645  1108.043433    0.082266  3.993566e+00   13.112582   \n",
      "20     1.000000     1.800000    0.360000  7.890000e-31    0.560000   \n",
      "21     0.750868    12.575000    0.052396  1.245660e-01   32.494722   \n",
      "22     0.820000    11.718182    0.053264  9.000000e-02   33.506529   \n",
      "23     0.512425    46.788207    0.056303  2.437873e-01   25.536475   \n",
      "24     0.665748     3.242424    0.098255  1.671258e-01   12.470156   \n",
      "25     1.000000     3.615385    0.069527  3.160000e-30   22.649408   \n",
      "26     0.702479     6.742424    0.051079  1.487603e-01   34.636823   \n",
      "27     0.586400     7.400000    0.148000  2.224000e-01    5.680000   \n",
      "28     1.000000     3.810811    0.102995  0.000000e+00   10.547845   \n",
      "29     0.219528    54.495737    0.066377  1.514211e+00   18.801206   \n",
      "30     0.903476     6.661017    0.056449  4.826199e-02   34.251652   \n",
      "31     0.612388   128.109396    0.042990  2.157555e-01   43.774372   \n",
      "..          ...          ...         ...           ...         ...   \n",
      "715    0.603306     9.646465    0.097439  1.983471e-01   10.276911   \n",
      "716    1.000000     5.825397    0.092467  7.890000e-31   12.132023   \n",
      "717    0.733121    10.110132    0.044538  1.334394e-01   54.704264   \n",
      "718    1.000000     5.800000    0.145000  0.000000e+00    4.377500   \n",
      "719    0.570312     3.250000    0.203125  2.148438e-01    5.875000   \n",
      "720    0.580387    10.111111    0.048846  2.098065e-01   36.011809   \n",
      "721    0.510668     7.943820    0.089256  2.446661e-01   10.181038   \n",
      "722    1.000000     3.000000    0.272727  0.000000e+00    1.289256   \n",
      "723    0.660474    20.098712    0.043130  1.697628e-01   54.189983   \n",
      "724    1.000000     3.105263    0.163435  0.000000e+00    6.260388   \n",
      "725    0.834711     3.000000    0.272727  8.264463e-02    2.793388   \n",
      "727    1.000000     7.037383    0.065770  7.890000e-31   22.118613   \n",
      "728    0.900277     4.052632    0.106648  4.986150e-02   14.903047   \n",
      "730    0.709343     3.352941    0.197232  1.453287e-01    2.408304   \n",
      "731    1.000000     1.666667    0.555556  0.000000e+00    0.222222   \n",
      "732    0.692176    21.280230    0.040845  1.539119e-01   52.211037   \n",
      "733    0.532318     6.932203    0.117495  2.338408e-01    8.559035   \n",
      "734    0.585849    10.988950    0.060712  2.070755e-01   24.984463   \n",
      "735    0.750537     5.247191    0.058957  1.247317e-01   29.289989   \n",
      "736    1.000000     5.080000    0.203200  7.890000e-31    2.201600   \n",
      "737    0.551879    23.360577    0.056155  2.240604e-01   26.957101   \n",
      "739    1.000000     5.112676    0.072010  7.890000e-31   18.963301   \n",
      "740    0.829121     6.792453    0.064080  8.543966e-02   25.827697   \n",
      "741    1.000000     5.666667    0.104938  7.890000e-31    7.899863   \n",
      "742    0.933413     9.975369    0.049140  3.329370e-02   39.067000   \n",
      "744    0.500247    11.300000    0.062778  2.498765e-01   23.090000   \n",
      "745    0.559911     7.935897    0.050871  2.200444e-01   39.062130   \n",
      "746    0.611497     7.000000    0.097222  1.942515e-01    9.962191   \n",
      "748    1.000000     9.142857    0.065306  3.160000e-30   21.418163   \n",
      "749    1.000000     3.545455    0.322314  0.000000e+00    1.900826   \n",
      "\n",
      "     radVar6094  radVar6095  outcome  \n",
      "0      4.459712    0.053134      1.0  \n",
      "1      4.825601    0.041715      1.0  \n",
      "2      4.746334    0.043692      1.0  \n",
      "3      3.823865    0.076855      1.0  \n",
      "4      4.596956    0.047128      1.0  \n",
      "5      4.782118    0.041876      1.0  \n",
      "6      3.597396    0.088950      1.0  \n",
      "7      1.148835    0.551020      1.0  \n",
      "8      3.108459    0.128906      1.0  \n",
      "9      4.939921    0.041160      1.0  \n",
      "10     4.194767    0.063673      1.0  \n",
      "11     3.750115    0.088000      1.0  \n",
      "12     4.790585    0.039670      1.0  \n",
      "13     1.392147    0.407407      1.0  \n",
      "14     5.486820    0.026635      1.0  \n",
      "15     4.647907    0.044319      1.0  \n",
      "16     4.284805    0.057631      1.0  \n",
      "17     6.521079    0.012815      1.0  \n",
      "20     1.521928    0.360000      1.0  \n",
      "21     4.502505    0.051146      1.0  \n",
      "22     4.430907    0.052727      1.0  \n",
      "23     5.235860    0.029719      1.0  \n",
      "24     3.899714    0.081726      1.0  \n",
      "25     3.981515    0.069527      1.0  \n",
      "26     4.469971    0.050620      1.0  \n",
      "27     3.577097    0.103200      1.0  \n",
      "28     3.396113    0.102995      1.0  \n",
      "29     6.109118    0.016730      1.0  \n",
      "30     4.306449    0.056449      1.0  \n",
      "31     5.292026    0.031230      1.0  \n",
      "..          ...         ...      ...  \n",
      "715    3.893330    0.077849      0.0  \n",
      "716    3.631810    0.092467      0.0  \n",
      "717    4.686590    0.043607      0.0  \n",
      "718    2.954347    0.145000      0.0  \n",
      "719    2.655639    0.171875      0.0  \n",
      "720    4.739034    0.042171      0.0  \n",
      "721    4.415349    0.052140      0.0  \n",
      "722    1.936260    0.272727      0.0  \n",
      "723    4.794774    0.040248      0.0  \n",
      "724    2.694781    0.163435      0.0  \n",
      "725    2.222192    0.272727      0.0  \n",
      "727    4.059617    0.065770      0.0  \n",
      "728    3.483834    0.106648      0.0  \n",
      "730    2.698660    0.183391      0.0  \n",
      "731    0.918296    0.555556      0.0  \n",
      "732    4.788768    0.039025      0.0  \n",
      "733    4.124192    0.066360      0.0  \n",
      "734    4.637806    0.045267      0.0  \n",
      "735    4.342065    0.053655      0.0  \n",
      "736    2.394303    0.203200      0.0  \n",
      "737    5.145447    0.032255      0.0  \n",
      "739    3.958428    0.072010      0.0  \n",
      "740    4.173551    0.063012      0.0  \n",
      "741    3.431293    0.104938      0.0  \n",
      "742    4.424833    0.049140      0.0  \n",
      "744    4.965721    0.036173      0.0  \n",
      "745    4.489543    0.048817      0.0  \n",
      "746    3.998032    0.077546      0.0  \n",
      "748    4.168858    0.065306      0.0  \n",
      "749    1.789929    0.322314      0.0  \n",
      "\n",
      "[705 rows x 6093 columns]\n",
      "(705, 6093)\n",
      "(493, 6092)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from tpot import TPOTClassifier\n",
    "import tools\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "file = \"endometrium.csv\"\n",
    "\n",
    "f = open(file)\n",
    "csv_f = csv.reader(f)\n",
    "features = next(csv_f)\n",
    "dataset = pd.read_csv(file, names=features, usecols=range(1,6097), dtype=np.float64, skiprows=1, low_memory=False)\n",
    "# INITIALIZING, CLEANING, AND STRATIFYING DATASET\n",
    "dataset['outcome'] = pd.to_numeric(dataset['outcome'], errors = 'coerce')\n",
    "dataset.dropna(axis=1, thresh=2, inplace=True)\n",
    "dataset.dropna(how='all',thresh = 20,inplace=True)\n",
    "#dataset = dataset[np.isfinite(dataset).all(1)]\n",
    "\n",
    "#\n",
    "array_OG = dataset.values\n",
    "wh_inf = np.isinf(array_OG)\n",
    "array_OG[wh_inf]=0\n",
    "wh_nan = np.isnan(array_OG)\n",
    "array_OG[wh_nan]=0\n",
    "print(dataset)\n",
    "print(array_OG.shape)\n",
    "X = array_OG[:,:6092]\n",
    "Y = array_OG[:,6092]\n",
    "# Y_og = Y_og.astype('int32')\n",
    "X = X.astype('float64')\n",
    "Y = Y.astype('int32')\n",
    "\n",
    "validation_size = 0.30\n",
    "seed = 7\n",
    "# X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X_og, Y_og, test_size=validation_size)\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 0 0 0 1 1 1 0 0 1 0 0 1 1 0 1 0 0 1 0 0 0 1 1 0 0 0 1 1 1 0 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 0 0 0 1 0\n",
      " 0 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1\n",
      " 0 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 0 0 1 0 0\n",
      " 1 1 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 1 0 0 0 1\n",
      " 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0]\n",
      "257\n"
     ]
    }
   ],
   "source": [
    "print(Y_test)\n",
    "#0 : 374 1 : 331\n",
    "train = Y_train[Y_train==0]\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb381ccf7bd433da056078f99d5feb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SEJveChjaGlsZHJlbj0oSW50UHJvZ3Jlc3ModmFsdWU9MCwgZGVzY3JpcHRpb249dSdPcHRpbWl6YXRpb24gUHJvZ3Jlc3MnLCBtYXg9MzAsIHN0eWxlPVByb2dyZXNzU3R5bGUoZGVzY3JpcHTigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.763336382016\n",
      "Generation 2 - Current best internal CV score: 0.763336382016\n",
      "Generation 3 - Current best internal CV score: 0.763336382016\n",
      "Generation 4 - Current best internal CV score: 0.780932345319\n",
      "Generation 5 - Current best internal CV score: 0.780932345319\n",
      "\n",
      "Best pipeline: KNeighborsClassifier(MaxAbsScaler(input_matrix), n_neighbors=35, p=1, weights=uniform)\n",
      "Accuracy: 0.7311320754716981\n",
      "Average Precision Score: 0.6229559748427673\n",
      "Kappa: 0.4664429530201343\n",
      "Hamming Loss: 0.2688679245283019\n",
      "AUC: 0.7376068376068377\n",
      "Sensitivity: 0.8\n",
      "Specificity: 0.6752136752136753\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "pipeline_optimizer = TPOTClassifier(generations=5, population_size=5, cv=5, verbosity=2, scoring='roc_auc',config_dict='TPOT light')\n",
    "pipeline_optimizer.fit(X_train, Y_train)\n",
    "Y_pred = pipeline_optimizer.predict(X_test)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_test, Y_pred)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_test, Y_pred)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_test, Y_pred)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_test, Y_pred)))\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_test, Y_pred)))\n",
    "print(\"Sensitivity: \" + repr(recall_score(Y_test, Y_pred)))\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, Y_pred).ravel()\n",
    "print(\"Specificity: \" + repr(tn / (tn + fp)))\n",
    "\n",
    "pipeline_optimizer.export('tpot_exported_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(pipeline_optimizer.fitted_pipeline_,'best.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7058823529411765\n",
      "Average Precision Score: 0.6228462826885346\n",
      "Kappa: 0.4156523587257731\n",
      "Hamming Loss: 0.29411764705882354\n",
      "AUC: 0.7095891314383698\n",
      "Sensitivity: 0.7966101694915254\n",
      "Specificity: 0.622568093385214\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load('best.pkl')\n",
    "Y_pred = model.predict(X_train)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_train,Y_pred)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_train, Y_pred)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_train, Y_pred)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_train, Y_pred)))\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_train, Y_pred)))\n",
    "print(\"Sensitivity: \" + repr(recall_score(Y_train, Y_pred)))\n",
    "tn, fp, fn, tp = confusion_matrix(Y_train, Y_pred).ravel()\n",
    "print(\"Specificity: \" + repr(tn / (tn + fp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=1050, style=ProgressStyle(descripâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.7105750487329434\n",
      "Generation 2 - Current best internal CV score: 0.7105750487329434\n",
      "Generation 3 - Current best internal CV score: 0.7105750487329434\n",
      "Generation 4 - Current best internal CV score: 0.7224508921877344\n",
      "Generation 5 - Current best internal CV score: 0.7224508921877344\n",
      "Generation 6 - Current best internal CV score: 0.7250599790073474\n",
      "Generation 7 - Current best internal CV score: 0.7250599790073474\n",
      "Generation 8 - Current best internal CV score: 0.7278977357924726\n",
      "Generation 9 - Current best internal CV score: 0.7278977357924726\n",
      "Generation 10 - Current best internal CV score: 0.7278977357924726\n",
      "Generation 11 - Current best internal CV score: 0.7420527815264657\n",
      "Generation 12 - Current best internal CV score: 0.7434472934472934\n",
      "Generation 13 - Current best internal CV score: 0.7434472934472934\n",
      "Generation 14 - Current best internal CV score: 0.7434472934472934\n",
      "Generation 15 - Current best internal CV score: 0.7434472934472934\n",
      "Generation 16 - Current best internal CV score: 0.7434472934472934\n",
      "Generation 17 - Current best internal CV score: 0.7434472934472934\n",
      "Generation 18 - Current best internal CV score: 0.7434472934472934\n",
      "Generation 19 - Current best internal CV score: 0.7434472934472934\n",
      "Generation 20 - Current best internal CV score: 0.7434472934472934\n",
      "\n",
      "Best pipeline: KNeighborsClassifier(MaxAbsScaler(SelectFwe(input_matrix, alpha=0.021)), n_neighbors=88, p=2, weights=distance)\n",
      "Accuracy: 0.6756756756756757\n",
      "Average Precision Score: 0.6726884354588873\n",
      "Kappa: 0.08306562643414428\n",
      "Hamming Loss: 0.32432432432432434\n",
      "AUC: 0.5326243691420331\n",
      "Sensitivity: 0.9863013698630136\n",
      "Specificity: 0.07894736842105263\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline_optimizer = TPOTClassifier(generations=20, population_size=50, cv=2, verbosity=2, scoring='roc_auc',config_dict='TPOT light')\n",
    "pipeline_optimizer.fit(X_train, Y_train)\n",
    "Y_pred = pipeline_optimizer.predict(X_test)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_test, Y_pred)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_test, Y_pred)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_test, Y_pred)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_test, Y_pred)))\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_test, Y_pred)))\n",
    "print(\"Sensitivity: \" + repr(recall_score(Y_test, Y_pred)))\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, Y_pred).ravel()\n",
    "print(\"Specificity: \" + repr(tn / (tn + fp)))\n",
    "\n",
    "pipeline_optimizer.export('tpot_exported_pipeline1.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
