{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(849, 6097)\n",
      "48\n",
      "8\n",
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntest_list\\n2\\n17\\n34\\n40\\n62\\n624\\n635\\n805\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "import joblib\n",
    "\n",
    "file_feature = \"./csv/endometrium.csv\"\n",
    "file_train = \"./csv/train.csv\"\n",
    "file_validate = \"./csv/validation.csv\"\n",
    "file_test = \"./csv/test.csv\"\n",
    "\n",
    "f = open(file_feature)\n",
    "csv_f = csv.reader(f)\n",
    "features = next(csv_f)\n",
    "dataset = pd.read_csv(file_feature, names=features, usecols=range(1,6098), dtype=np.float64, skiprows=1, low_memory=False)\n",
    "f = open(file_train)\n",
    "csv_f = csv.reader(f)\n",
    "features = next(csv_f)\n",
    "dataset_train = pd.read_csv(file_train, names=features, usecols=range(1,1), dtype=np.float64, skiprows=1, low_memory=False)\n",
    "\n",
    "with open('./csv/train.csv','r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    train_list = [row[1] for row in reader]\n",
    "with open('./csv/validation.csv','r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    validation_list = [row['patient'] for row in reader]\n",
    "with open('./csv/test.csv','r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    test_list = [row['patient'] for row in reader]\n",
    "\n",
    "dataset['outcome'] = pd.to_numeric(dataset['outcome'],errors='coerce')\n",
    "array_OG = dataset.values\n",
    "print(array_OG.shape)\n",
    "train_list = train_list[1:]\n",
    "validation_list = validation_list[0:]\n",
    "test_list = test_list[0:]\n",
    "#print(test_list)\n",
    "#print(train_list)\n",
    "#print(validation_list)\n",
    "\n",
    "def cat_str(num_list):\n",
    "    n_list = []\n",
    "    for i in num_list:\n",
    "        temp = i[12:]\n",
    "        n_list.append(temp)\n",
    "    n_list = [int(x) for x in n_list]\n",
    "    return n_list\n",
    "\n",
    "train_list = cat_str(train_list)\n",
    "validation_list = cat_str(validation_list)\n",
    "test_list = cat_str(test_list)\n",
    "\n",
    "#print(train_list)\n",
    "#print(validation_list)\n",
    "#print(test_list)\n",
    "#print(len(test_list))\n",
    "\n",
    "CT = [1,2,7,12,16,17,29,30,31,33,34,35,37,38,40,42,45,51,54,56,57,58,59,60,62,67,69,79,84,109,110,116,119,137,138,143,404,147,155,156,161,201,232,248,256,269,278,624,635,646,650,358,366,379,393,395,561,689,693,702,737,778,789,805]\n",
    "        \n",
    "new_train = []\n",
    "new_validation = []\n",
    "new_test = []\n",
    "for i in CT:\n",
    "    if i in test_list:\n",
    "        new_test.append(i)\n",
    "    if i in validation_list:\n",
    "        new_validation.append(i)\n",
    "    if i in train_list:\n",
    "        new_train.append(i)\n",
    "\n",
    "print(len(new_train))\n",
    "print(len(new_validation))\n",
    "print(len(new_test))\n",
    "\n",
    "train_list = new_train\n",
    "validation_list = new_validation\n",
    "test_list = new_test\n",
    "        \n",
    "'''\n",
    "train_list:\n",
    "1\n",
    "12\n",
    "29\n",
    "30\n",
    "31\n",
    "35\n",
    "37\n",
    "38\n",
    "42\n",
    "45\n",
    "51\n",
    "54\n",
    "57\n",
    "58\n",
    "60\n",
    "67\n",
    "79\n",
    "84\n",
    "109\n",
    "110\n",
    "116\n",
    "119\n",
    "137\n",
    "138\n",
    "143\n",
    "404\n",
    "147\n",
    "155\n",
    "156\n",
    "161\n",
    "201\n",
    "232\n",
    "248\n",
    "256\n",
    "269\n",
    "278\n",
    "646\n",
    "650\n",
    "358\n",
    "366\n",
    "379\n",
    "393\n",
    "395\n",
    "561\n",
    "689\n",
    "693\n",
    "778\n",
    "789\n",
    "'''\n",
    "\n",
    "'''\n",
    "validation_list\n",
    "7\n",
    "16\n",
    "33\n",
    "56\n",
    "59\n",
    "69\n",
    "702\n",
    "737\n",
    "'''\n",
    "\n",
    "'''\n",
    "test_list\n",
    "2\n",
    "17\n",
    "34\n",
    "40\n",
    "62\n",
    "624\n",
    "635\n",
    "805\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "train_feature = []\n",
    "validate_feature = []\n",
    "test_feature = []\n",
    "count = 1\n",
    "for i in range(len(array_OG)):\n",
    "    num = i + 1\n",
    "    if num in train_list:\n",
    "        train_feature.append(array_OG[i])\n",
    "    elif num in validation_list:\n",
    "        validate_feature.append(array_OG[i])\n",
    "    elif num in test_list:\n",
    "        #print(count)\n",
    "        count = count + 1\n",
    "        test_feature.append(array_OG[i])\n",
    "        \n",
    "train_feature = np.array(train_feature)\n",
    "validate_feature = np.array(validate_feature)\n",
    "test_feature = np.array(test_feature)\n",
    "\n",
    "train_feature = pd.DataFrame(train_feature)\n",
    "train_feature.dropna(axis=1, thresh=2, inplace=True)\n",
    "#train_feature.dropna(how='all',thresh = 20,inplace=True)\n",
    "train_feature = np.array(train_feature)\n",
    "wh_inf = np.isinf(train_feature)\n",
    "train_feature[wh_inf]=0\n",
    "wh_nan = np.isnan(train_feature)\n",
    "train_feature[wh_nan]=0\n",
    "\n",
    "validate_feature = pd.DataFrame(validate_feature)\n",
    "validate_feature.dropna(axis=1, thresh=2, inplace=True)\n",
    "#validate_feature.dropna(how='all',thresh = 20,inplace=True)\n",
    "validate_feature = np.array(validate_feature)\n",
    "wh_inf = np.isinf(validate_feature)\n",
    "validate_feature[wh_inf]=0\n",
    "wh_nan = np.isnan(validate_feature)\n",
    "validate_feature[wh_nan]=0\n",
    "\n",
    "test_feature = pd.DataFrame(test_feature)\n",
    "test_feature.dropna(axis=1, thresh=2, inplace=True)\n",
    "#test_feature.dropna(how='all',thresh = 20,inplace=True)\n",
    "test_feature = np.array(test_feature)\n",
    "wh_inf = np.isinf(test_feature)\n",
    "test_feature[wh_inf]=0\n",
    "wh_nan = np.isnan(test_feature)\n",
    "test_feature[wh_nan]=0\n",
    "\n",
    "#only use image features\n",
    "X_train = train_feature[:,:6093]\n",
    "Y_train = train_feature[:,6093]\n",
    "Y_train = Y_train.astype('int32')\n",
    "\n",
    "X_validate = validate_feature[:,:6093]\n",
    "Y_validate = validate_feature[:,6093]\n",
    "Y_validate = Y_validate.astype('int32')\n",
    "\n",
    "X_test = test_feature[:,:6093]\n",
    "Y_test = test_feature[:,6093]\n",
    "Y_test = Y_test.astype('int32')\n",
    "\n",
    "\n",
    "print(len(Y_train))\n",
    "print(len(Y_validate))\n",
    "print(len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.875\n",
      "Average Precision Score: 0.9583333333333334\n",
      "Kappa: 0.7142857142857143\n",
      "Hamming Loss: 0.125\n",
      "AUC0.9166666666666667\n",
      "Sensitivity0.8333333333333334\n",
      "Specificity1.0\n",
      "2 0 1 5\n"
     ]
    }
   ],
   "source": [
    "pipe = joblib.load('./handpkl/EndoBAGRELF20.pkl')\n",
    "Y_pred = pipe.predict(X_validate)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_validate, Y_pred)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_validate, Y_pred)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_validate, Y_pred)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_validate, Y_pred)))\n",
    "print(\"AUC\"+repr(roc_auc_score(Y_validate,Y_pred)))\n",
    "print(\"Sensitivity\" + repr(recall_score(Y_validate,Y_pred)))\n",
    "tn,fp,fn,tp = confusion_matrix(Y_validate,Y_pred).ravel()\n",
    "print(\"Specificity\" + repr(tn/(tn+fp)))\n",
    "print(tn,fp,fn,tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in Y_validate:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "Average Precision Score: 0.9642857142857143\n",
      "Kappa: 0.3846153846153846\n",
      "Hamming Loss: 0.25\n",
      "Sensitivity0.7142857142857143\n",
      "Specificity1.0\n",
      "1 0 2 5\n"
     ]
    }
   ],
   "source": [
    "Y_pred = pipe.predict(X_test)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_test, Y_pred)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_test, Y_pred)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_test, Y_pred)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_test, Y_pred)))\n",
    "print(\"Sensitivity\" + repr(recall_score(Y_test,Y_pred)))\n",
    "tn,fp,fn,tp = confusion_matrix(Y_test,Y_pred).ravel()\n",
    "print(\"Specificity\" + repr(tn/(tn+fp)))\n",
    "print(tn,fp,fn,tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in Y_test:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8958333333333334\n",
      "Average Precision Score: 0.9489931107578167\n",
      "Kappa: 0.7309417040358744\n",
      "Hamming Loss: 0.10416666666666667\n",
      "AUC: 0.9004914004914005\n",
      "Sensitivity: 0.8918918918918919\n",
      "Specificity: 0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "Y_pred = pipe.predict(X_train)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_train, Y_pred)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_train, Y_pred)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_train, Y_pred)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_train, Y_pred)))\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_train, Y_pred)))\n",
    "print(\"Sensitivity: \" + repr(recall_score(Y_train, Y_pred)))\n",
    "tn, fp, fn, tp = confusion_matrix(Y_train, Y_pred).ravel()\n",
    "print(\"Specificity: \" + repr(tn / (tn + fp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in Y_train:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
